{
  "pk": "id#f5e6304df82d10f3",
  "path": "UTC#2025-12-03/id#f5e6304df82d10f3.xml",
  "tickers": [
    "NVDA",
    "AMD"
  ],
  "published_at": "2025-12-03T13:00:04.429499-05:00",
  "source": null,
  "title": "Nvidia servers speed up AI models from China's Moonshoot AI and others tenfold",
  "article_raw": "<article><pk>id#f5e6304df82d10f3</pk><url>https://finance.yahoo.com/news/nvidia-servers-speed-ai-models-173320148.html</url><provider>Reuters</provider><author>Stephen Nellis</author><publish_iso_utc>2025-12-03T17:43:14Z</publish_iso_utc><publish_et_iso>2025-12-03T12:43:14-05:00</publish_et_iso><body>&lt;![CDATA[\nBy Stephen Nellis\n\nSAN FRANCISCO, Dec 3 (Reuters) - Nvidia (NVDA) on Wednesday published new data showing that its latest artificial intelligence server can improve the performance ​of new models - including two popular ones from China - by 10 times.\n\nThe ‌data comes as the AI world has shifted its focus from training AI models, where Nvidia dominates ‌the market, to putting them to use for millions of users, where Nvidia faces far more competition from rivals such as Advanced Micro Devices and Cerebras.\n\nNvidia's data focused on what are known as mixture-of-expert AI models. The technique is a way of making ⁠AI models more efficient by ‌breaking up questions into pieces that are assigned to \"experts\" within the model. That exploded in popularity this year after China's DeepSeek ‍shocked the world with a high-performing open source model that took less training on Nvidia chips than rivals in early 2025.\n\nSince then, the mixture-of-experts approach has been adopted by ChatGPT maker ​OpenAI, France's Mistral and China's Moonshoot AI, which in July released a ‌highly-ranked open source model of its own.\n\nMeanwhile, Nvidia has focused on making the case that while such models might require less training on its chips, its offerings can still be used to serve those models to users.\n\nNvidia on Wednesday said that its latest AI server, which packs 72 of its leading chips into a single ⁠computer with speedy links between them, improved the ​performance of Moonshot's Kimi K2 Thinking model by ​10 times compared to the previous generation of Nvidia servers, a similar performance gain to what Nvidia has seen with DeepSeek's models.\n\nNvidia said the ‍gains primarily came ⁠from the sheer number of chips it can pack into servers and the fast links between them, an area where Nvidia still has advantages over ⁠its rivals.\n\nNvidia competitor AMD (AMD) is working on a similar server packed with multiple powerful chips that it ‌has said will come to market next year.\n\n(Reporting by Stephen Nellis ‌in San Francisco, editing by Deepa Babington)\n]]&gt;</body></article>",
  "article_text": "id#f5e6304df82d10f3\nhttps://finance.yahoo.com/news/nvidia-servers-speed-ai-models-173320148.html\nReuters\nStephen Nellis\n2025-12-03T17:43:14Z\n2025-12-03T12:43:14-05:00\n<![CDATA[\nBy Stephen Nellis\n\nSAN FRANCISCO, Dec 3 (Reuters) - Nvidia (NVDA) on Wednesday published new data showing that its latest artificial intelligence server can improve the performance ​of new models - including two popular ones from China - by 10 times.\n\nThe ‌data comes as the AI world has shifted its focus from training AI models, where Nvidia dominates ‌the market, to putting them to use for millions of users, where Nvidia faces far more competition from rivals such as Advanced Micro Devices and Cerebras.\n\nNvidia's data focused on what are known as mixture-of-expert AI models. The technique is a way of making ⁠AI models more efficient by ‌breaking up questions into pieces that are assigned to \"experts\" within the model. That exploded in popularity this year after China's DeepSeek ‍shocked the world with a high-performing open source model that took less training on Nvidia chips than rivals in early 2025.\n\nSince then, the mixture-of-experts approach has been adopted by ChatGPT maker ​OpenAI, France's Mistral and China's Moonshoot AI, which in July released a ‌highly-ranked open source model of its own.\n\nMeanwhile, Nvidia has focused on making the case that while such models might require less training on its chips, its offerings can still be used to serve those models to users.\n\nNvidia on Wednesday said that its latest AI server, which packs 72 of its leading chips into a single ⁠computer with speedy links between them, improved the ​performance of Moonshot's Kimi K2 Thinking model by ​10 times compared to the previous generation of Nvidia servers, a similar performance gain to what Nvidia has seen with DeepSeek's models.\n\nNvidia said the ‍gains primarily came ⁠from the sheer number of chips it can pack into servers and the fast links between them, an area where Nvidia still has advantages over ⁠its rivals.\n\nNvidia competitor AMD (AMD) is working on a similar server packed with multiple powerful chips that it ‌has said will come to market next year.\n\n(Reporting by Stephen Nellis ‌in San Francisco, editing by Deepa Babington)\n]]>"
}